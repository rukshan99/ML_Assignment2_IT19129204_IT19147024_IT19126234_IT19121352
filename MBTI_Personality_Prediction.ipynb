{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d81464",
   "metadata": {},
   "source": [
    "# Myers–Briggs Type Indicator (MBTI) Personality Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41605ba",
   "metadata": {},
   "source": [
    "## Libraries and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17a8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ipywidgets import widgets, interact\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b8dd9",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef389ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"mbti_normalized.csv\"):\n",
    "    df = pd.read_csv('mbti_1.csv', encoding='utf8')\n",
    "else:\n",
    "    df = pd.read_csv('mbti_normalized.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c759e2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>moment sportscenter play prank life change exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>find lack post alarming sex boring position ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>good course know blessing curse absolutely pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>dear enjoy conversation day esoteric gabbe nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>fire silly misconception approach logically ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'18/37 @.@|||Science  is not perfect. No scien...</td>\n",
       "      <td>Science perfect scientist claim scientific inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>'No, I can't draw on my own nails (haha). Thos...</td>\n",
       "      <td>draw nail haha professional nail yes gel mean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'I tend to build up a collection of things on ...</td>\n",
       "      <td>tend build collection thing desktop use freque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>I'm not sure, that's a good question. The dist...</td>\n",
       "      <td>sure good question distinction dependant perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>INTP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=w8-egj0y8Qs||...</td>\n",
       "      <td>position actually let person reason unfortunat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                              posts  \\\n",
       "0           0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1           1  ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2           2  INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3           3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4           4  ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "5           5  INTJ  '18/37 @.@|||Science  is not perfect. No scien...   \n",
       "6           6  INFJ  'No, I can't draw on my own nails (haha). Thos...   \n",
       "7           7  INTJ  'I tend to build up a collection of things on ...   \n",
       "8           8  INFJ  I'm not sure, that's a good question. The dist...   \n",
       "9           9  INTP  'https://www.youtube.com/watch?v=w8-egj0y8Qs||...   \n",
       "\n",
       "                                     normalized_text  \n",
       "0  moment sportscenter play prank life change exp...  \n",
       "1  find lack post alarming sex boring position ex...  \n",
       "2  good course know blessing curse absolutely pos...  \n",
       "3  dear enjoy conversation day esoteric gabbe nat...  \n",
       "4  fire silly misconception approach logically ke...  \n",
       "5  Science perfect scientist claim scientific inf...  \n",
       "6  draw nail haha professional nail yes gel mean ...  \n",
       "7  tend build collection thing desktop use freque...  \n",
       "8  sure good question distinction dependant perce...  \n",
       "9  position actually let person reason unfortunat...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f273da76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8675 entries, 0 to 8674\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       8675 non-null   int64 \n",
      " 1   type             8675 non-null   object\n",
      " 2   posts            8675 non-null   object\n",
      " 3   normalized_text  8674 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 271.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5911ece",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ea6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b13a907f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8832e849",
   "metadata": {},
   "source": [
    "### Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aeec7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(sentence):\n",
    " \n",
    "    # Remove ||| from kaggle dataset\n",
    "    sentence = re.sub(\"[]|||[]\", \" \", sentence)\n",
    "\n",
    "    # remove reddit subreddit urls\n",
    "    sentence = re.sub(\"/r/[0-9A-Za-z]\", \"\", sentence)\n",
    "\n",
    "    # remove MBTI types\n",
    "    MBTI_types = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "              'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ',\n",
    "              'MBTI']\n",
    "    MBTI_types = [ti.lower() for ti in MBTI_types] + [ti.lower() + 's' for ti in MBTI_types]\n",
    "\n",
    "    tokens = nlp(sentence)\n",
    "\n",
    "    tokens = [ti for ti in tokens if ti.lower_ not in STOP_WORDS]\n",
    "    tokens = [ti for ti in tokens if not ti.is_space]\n",
    "    tokens = [ti for ti in tokens if not ti.is_punct]\n",
    "    tokens = [ti for ti in tokens if not ti.like_num]\n",
    "    tokens = [ti for ti in tokens if not ti.like_url]\n",
    "    tokens = [ti for ti in tokens if not ti.like_email]\n",
    "    tokens = [ti for ti in tokens if ti.lower_ not in MBTI_types]\n",
    "\n",
    "\n",
    "    # lemmatize\n",
    "    tokens = [ti.lemma_ for ti in tokens if ti.lemma_ not in STOP_WORDS]\n",
    "    tokens = [ti for ti in tokens if len(ti) > 1]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acfd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"mbti_normalized.csv\"):\n",
    "    df['normalized_text'] = df.posts.apply(normalizer)\n",
    "    df.to_csv('mbti_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f69cb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>moment sportscenter play prank life change exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>find lack post alarming sex boring position ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>good course know blessing curse absolutely pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>dear enjoy conversation day esoteric gabbe nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>fire silly misconception approach logically ke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                              posts  \\\n",
       "0           0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1           1  ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2           2  INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3           3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4           4  ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "\n",
       "                                     normalized_text  \n",
       "0  moment sportscenter play prank life change exp...  \n",
       "1  find lack post alarming sex boring position ex...  \n",
       "2  good course know blessing curse absolutely pos...  \n",
       "3  dear enjoy conversation day esoteric gabbe nat...  \n",
       "4  fire silly misconception approach logically ke...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa85024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>moment sportscenter play prank life change exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>find lack post alarming sex boring position ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good course know blessing curse absolutely pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear enjoy conversation day esoteric gabbe nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire silly misconception approach logically ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>IxFP think cat Fi dom reason especially websit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread exist someplace heck delete ooop guess ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>question thing purple pill pick win lottery nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right come want child honestly mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long personalitycafe change bit good like usua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                    normalized_text\n",
       "0     INFJ  moment sportscenter play prank life change exp...\n",
       "1     ENTP  find lack post alarming sex boring position ex...\n",
       "2     INTP  good course know blessing curse absolutely pos...\n",
       "3     INTJ  dear enjoy conversation day esoteric gabbe nat...\n",
       "4     ENTJ  fire silly misconception approach logically ke...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  IxFP think cat Fi dom reason especially websit...\n",
       "8671  ENFP  thread exist someplace heck delete ooop guess ...\n",
       "8672  INTP  question thing purple pill pick win lottery nu...\n",
       "8673  INFP  conflicted right come want child honestly mate...\n",
       "8674  INFP  long personalitycafe change bit good like usua...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnamed columns\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.drop(df.columns[1], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e155db7",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07de83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef280237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6522</th>\n",
       "      <td>INFP</td>\n",
       "      <td>confusion inner feeling ignore notice picture ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>leave excuse partial self promotion like know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>time mention chance address clear mean depend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>Contra personally live debate Blair White fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>eh type politician political argument happen a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>hauhuhauh right Muhicz wonder step come exactl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>read comic_strip base film Professor James McA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6519</th>\n",
       "      <td>INFP</td>\n",
       "      <td>love find think Beverly pretty typical Murray ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>INFP</td>\n",
       "      <td>self confidence feel like impossible change kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>INFP</td>\n",
       "      <td>today :D amazing pretty total solar eclipse pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6940 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                    normalized_text\n",
       "6522  INFP  confusion inner feeling ignore notice picture ...\n",
       "3553  INTJ  leave excuse partial self promotion like know ...\n",
       "6718  INFJ  time mention chance address clear mean depend ...\n",
       "428   ENFP  Contra personally live debate Blair White fund...\n",
       "6276  ENTP  eh type politician political argument happen a...\n",
       "...    ...                                                ...\n",
       "360   ENFP  hauhuhauh right Muhicz wonder step come exactl...\n",
       "4189  INFJ  read comic_strip base film Professor James McA...\n",
       "6519  INFP  love find think Beverly pretty typical Murray ...\n",
       "3266  INFP  self confidence feel like impossible change kn...\n",
       "5114  INFP  today :D amazing pretty total solar eclipse pa...\n",
       "\n",
       "[6940 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c362d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['normalized_text']\n",
    "y_train = train['type']\n",
    "X_test = test['normalized_text']\n",
    "y_test = test['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62641e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 6940, n_features: 80779\n"
     ]
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train_tf = tf_idf.fit_transform(X_train.values.astype('U'))\n",
    "X_train_tf = tf_idf.transform(X_train.values.astype('U'))\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5dc0569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 1735, n_features: 80779\n"
     ]
    }
   ],
   "source": [
    "X_test_tf = tf_idf.transform(X_test.values.astype('U'))\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47713abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_tf\n",
    "X_test = X_test_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "264d8e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1735, 80779)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4b45b",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31c2f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"model_lr.pickle\"):\n",
    "    # parameter grid\n",
    "    parameters_lr = {\n",
    "        'penalty' : ['l1', 'l2'], \n",
    "        'C'       : np.logspace(-4, 4, 20),\n",
    "        'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        'max_iter' : [50, 100, 1000, 2500, 5000]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ba02d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " model_LR_CON: best estimator across ALL searched params:\n",
      " LogisticRegression(C=78.47599703514607, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=50, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      " model_LR_CON: best parameters across ALL searched params:\n",
      " {'C': 78.47599703514607, 'max_iter': 50, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(\"model_lr.pickle\"):\n",
    "    model_LR = GridSearchCV(LogisticRegression(), param_grid = parameters_lr, scoring='accuracy', cv=5)\n",
    "    model_LR = model_LR.fit(X_train, y_train)\n",
    "    print(\"\\n model_LR: best estimator across ALL searched params:\\n\",model_LR.best_estimator_)\n",
    "    print(\"\\n model_LR: best parameters across ALL searched params:\\n\",model_LR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce66e6",
   "metadata": {},
   "source": [
    "**After applying GridSearchCV for the Logistic Regression model,**\n",
    "\n",
    "* The best estimator across ALL searched params = \n",
    "            LogisticRegression(C=78.47599703514607, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=50, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "                   \n",
    "* The best parameters across ALL searched params = \n",
    "            {'C': 78.47599703514607, 'max_iter': 50, 'penalty': 'l2', 'solver': 'newton-cg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0449264",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression(C=78.47599703514607, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=50, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "model_LR = model_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dba3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_LR = model_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"model_lr.pickle\"):\n",
    "    # Pickle the model\n",
    "    with open('model_lr.pickle', 'wb') as files:\n",
    "        pickle.dump(model_LR, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3053e65",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dece4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4207492795389049"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculatingthe accuracy of the KNN model\n",
    "accuracy = accuracy_score(y_test, output_LR)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad5839",
   "metadata": {},
   "source": [
    "## Example: how to use a pickled model for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e8437",
   "metadata": {},
   "source": [
    "```\n",
    "with open('model_lr.pickle', 'rb') as f:\n",
    "    pickled_model_lr = pickle.load(f)\n",
    "\n",
    "text = 'When I was just a little girl, I keep to myself, I hardly talk to people, even when I’m in school I don’t talk to my friends in class. Most times when my teacher ask me a question, she forces words out of my mouth. My mum told me all this.'\n",
    "\n",
    "normalized_text = normalizer(text)\n",
    "vectorized_text = tf_idf.transform([normalized_text])\n",
    "prediction = pickled_model_lr.predict(vectorized_text)\n",
    "\n",
    "prediction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10c29d",
   "metadata": {},
   "source": [
    "## Reference\n",
    "M. J, (MBTI) Myers-Briggs Personality Type Dataset, 2017, Kaggle, May 2022. [Online]. Available: https://www.kaggle.com/datasnaek/mbti-type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017708b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
